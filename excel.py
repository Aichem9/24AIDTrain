import streamlit as st
import pandas as pd
import openai
import matplotlib.pyplot as plt
from dotenv import load_dotenv
import os

# Load environment variables, including API keys
load_dotenv()

# Set OpenAI API key
openai.api_key = os.getenv("")

st.title("ğŸ“Š ì—‘ì…€ ë°ì´í„° ë¶„ì„, ì‹œê°í™” ë° GPT í”¼ë“œë°± ìƒì„±ê¸° ğŸ“")

# Initialize session state for messages and analysis chain
if "messages" not in st.session_state:
    st.session_state["messages"] = []

if "analysis_chain" not in st.session_state:
    st.session_state["analysis_chain"] = None

# Sidebar for file upload and model selection
with st.sidebar:
    # Initialization button
    clear_btn = st.button("ì´ˆê¸°í™”")

    # Upload Excel file
    uploaded_file = st.file_uploader("íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx", "xls"])

    # Select model for summarization and feedback
    selected_model = st.selectbox(
        "LLM ì„ íƒ", ["gpt-3.5-turbo", "gpt-4"], index=0
    )

    # Button to update settings
    update_btn = st.button("ì„¤ì • ì—…ë°ì´íŠ¸")

# Function to display previous messages
def print_messages():
    for chat_message in st.session_state["messages"]:
        st.chat_message(chat_message["role"]).write(chat_message["content"])

# Function to add a new message to the session state
def add_message(role, message):
    st.session_state["messages"].append({"role": role, "content": message})

# Function to process and analyze the uploaded Excel file
@st.cache_data(show_spinner="ì—…ë¡œë“œí•œ íŒŒì¼ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤...")
def analyze_excel(file):
    # Load Excel data into a DataFrame
    df = pd.read_excel(file)
    return df

# Function to create a prompt for GPT
def create_prompt(data_summary):
    prompt = f"""
    Here is a summary of the dataset:

    {data_summary}

    Please provide a detailed analysis and give constructive feedback for improving the dataset.
    """
    return prompt

# Function to query OpenAI API for analysis and feedback
def query_openai(prompt, model="gpt-3.5-turbo"):
    response = openai.ChatCompletion.create(
        model=model,
        messages=[
            {"role": "system", "content": "You are a data analysis assistant."},
            {"role": "user", "content": prompt}
        ],
        max_tokens=500
    )
    return response.choices[0].message["content"]

# Function to visualize the data
def visualize_data(df):
    st.write("### ë°ì´í„° ì‹œê°í™”:")

    # ê¸°ë³¸ í†µê³„ ì‹œê°í™”
    st.write("#### ë°ì´í„° ë¶„í¬ íˆìŠ¤í† ê·¸ë¨:")
    numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns.tolist()
    if numeric_columns:
        selected_column = st.selectbox("ì—´ ì„ íƒ", numeric_columns)
        plt.figure(figsize=(10, 6))
        plt.hist(df[selected_column], bins=20, color='skyblue', edgecolor='black')
        plt.title(f'{selected_column}ì˜ ë¶„í¬')
        plt.xlabel(selected_column)
        plt.ylabel('Frequency')
        st.pyplot(plt)
    else:
        st.write("ìˆ˜ì¹˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
    st.write("#### ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ:")
    if len(numeric_columns) > 1:
        correlation_matrix = df.corr()
        plt.figure(figsize=(10, 6))
        plt.imshow(correlation_matrix, cmap='coolwarm', interpolation='nearest')
        plt.colorbar()
        plt.xticks(range(len(correlation_matrix.columns)), correlation_matrix.columns, rotation=45)
        plt.yticks(range(len(correlation_matrix.columns)), correlation_matrix.columns)
        plt.title("ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ")
        st.pyplot(plt)
    else:
        st.write("ìƒê´€ê´€ê³„ë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆëŠ” ì¶©ë¶„í•œ ìˆ˜ì¹˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# Process the uploaded file and generate analysis and feedback
if uploaded_file:
    df = analyze_excel(uploaded_file)
    st.write("### ì—‘ì…€ ë°ì´í„°:")
    st.write(df)

    # Generate a simple summary of the data
    data_summary = df.describe(include='all').to_string()

    # Create the prompt for GPT
    prompt = create_prompt(data_summary)

    # Query OpenAI's GPT model
    with st.spinner("GPT ëª¨ë¸ì„ í†µí•´ ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        gpt_response = query_openai(prompt, model=selected_model)

    st.write("### GPT í”¼ë“œë°±:")
    st.write(gpt_response)

    # Save the GPT response in session state
    st.session_state["analysis_chain"] = gpt_response

    # Visualize the data
    visualize_data(df)

# Clear previous messages if the button is clicked
if clear_btn:
    st.session_state["messages"] = []
    st.session_state["analysis_chain"] = None

# Update chain settings if the button is clicked
if update_btn and uploaded_file:
    df = analyze_excel(uploaded_file)
    data_summary = df.describe(include='all').to_string()
    prompt = create_prompt(data_summary)
    gpt_response = query_openai(prompt, model=selected_model)
    st.session_state["analysis_chain"] = gpt_response
    visualize_data(df)

# Display previous messages
print_messages()

# Input for user queries
user_input = st.chat_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”!")

# Process user input and generate response
if user_input:
    if st.session_state["analysis_chain"] is not None:
        st.chat_message("user").write(user_input)

        # Append the user's question to the conversation
        st.session_state["messages"].append({"role": "user", "content": user_input})
        response = query_openai(user_input, model=selected_model)

        with st.chat_message("assistant"):
            container = st.empty()
            container.markdown(response)

        # Save chat history
        add_message("user", user_input)
        add_message("assistant", response)
    else:
        st.error("ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.")
